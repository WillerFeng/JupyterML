{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "PATH = '/Users/willer/Downloads/'\n",
    "TRAIN_abbr = pd.read_csv(PATH + \"happiness_train_abbr.csv\",encoding='ISO-8859-1')\n",
    "TRAIN = pd.read_csv(PATH + \"happiness_train_complete.csv\",encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 42)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_abbr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 140)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = TRAIN[TRAIN['happiness'] > 0]\n",
    "LABEL = TRAIN['happiness']\n",
    "TRAIN[\"survey_month\"] = TRAIN[\"survey_time\"].map(lambda line:line.split(\" \")[0].split(\"/\")[1]).astype(\"int64\")\n",
    "TRAIN[\"survey_day\"] = TRAIN[\"survey_time\"].map(lambda line:line.split(\" \")[0].split(\"/\")[2]).astype(\"int64\")\n",
    "TRAIN[\"survey_hour\"] = TRAIN[\"survey_time\"].map(lambda line:line.split(\" \")[1].split(\":\")[0]).astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_list = [\"happiness\",\"survey_time\",\"edu_other\",\"property_other\",\"invest_other\"]\n",
    "for item in del_list:\n",
    "    del TRAIN[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble.gradient_boosting import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "import lightgbm as lgb\n",
    "from lightgbm.sklearn import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-068102bd225a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m                           silent=True)\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mrf_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mxg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrf_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 542\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=5)\n",
    "score = []\n",
    "for train, test in kfold.split(TRAIN):\n",
    "    x_train = TRAIN.iloc[train]\n",
    "    y_train = LABEL.iloc[train]\n",
    "    x_test = TRAIN.iloc[test]\n",
    "    y_test = LABEL.iloc[test]\n",
    "    \n",
    "    rf = RandomForestRegressor(n_estimators=400, \n",
    "                               criterion='mse', \n",
    "                               max_depth=5, \n",
    "                               max_features=5)\n",
    "    \n",
    "    xg = XGBRegressor(n_estimators=100, \n",
    "                      max_depth=5, \n",
    "                      objective='reg:squarederror')\n",
    "    \n",
    "    lg = LGBMRegressor(n_estimators=100, \n",
    "                       max_depth=5)\n",
    "    \n",
    "    ct = CatBoostRegressor(iterations=800, \n",
    "                          depth=5, \n",
    "                          learning_rate=0.05, \n",
    "                          loss_function='RMSE',\n",
    "                          silent=True)\n",
    "    \n",
    "    #rf.fit(x_train, y_train)\n",
    "    rf_y = y_train\n",
    "    xg.fit(x_train, rf_y)\n",
    "    loss_xg = rf_y - xg.predict(x_train)\n",
    "    lg.fit(x_train, rf_y)\n",
    "    loss_lg = rf_y - lg.predict(x_train)\n",
    "    ct.fit(x_train, rf_y)\n",
    "    loss_ct = rf_y - ct.predict(x_train)\n",
    "    \n",
    "    \n",
    "    catX = ct.predict(x_test)\n",
    "    xgX = xg.predict(x_test)\n",
    "    lgX = lg.predict(x_test)\n",
    "    res = np.c_[xgX,lgX,catX]\n",
    "    e = np.array([1/np.mean(loss_xg),1/np.mean(loss_lg),1/np.mean(loss_ct)])\n",
    "    y_pred = np.sum(res*e,axis=1)/sum(e)\n",
    "    \n",
    "    e_test = mean_squared_error(y_true=y_test,y_pred=y_pred)\n",
    "    score.append(e_test)\n",
    "print(score)\n",
    "print(sum(score)/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = pd.read_csv(PATH + 'happiness_test_complete.csv',encoding='ISO-8859-1')\n",
    "TEST[\"survey_month\"] = TEST[\"survey_time\"].map(lambda line:line.split(\" \")[0].split(\"/\")[1]).astype(\"int64\")\n",
    "TEST[\"survey_day\"] = TEST[\"survey_time\"].map(lambda line:line.split(\" \")[0].split(\"/\")[2]).astype(\"int64\")\n",
    "TEST[\"survey_hour\"] = TEST[\"survey_time\"].map(lambda line:line.split(\" \")[1].split(\":\")[0]).astype(\"int64\")\n",
    "del_list = [\"survey_time\",\"edu_other\",\"property_other\",\"invest_other\"]\n",
    "for item in del_list:\n",
    "    del TEST[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf = RandomForestRegressor(n_estimators=400, \n",
    "                               criterion='mse', \n",
    "                               max_depth=5, \n",
    "                               max_features=5)\n",
    "    \n",
    "xg = XGBRegressor(n_estimators=100, \n",
    "                  max_depth=5, \n",
    "                  objective='reg:squarederror')\n",
    "\n",
    "lg = LGBMRegressor(n_estimators=100, \n",
    "                   max_depth=5)\n",
    "\n",
    "ct = CatBoostRegressor(iterations=800, \n",
    "                      depth=5, \n",
    "                      learning_rate=0.05, \n",
    "                      loss_function='RMSE',\n",
    "                      silent=True)\n",
    "rf_y = LABEL\n",
    "xg.fit(TRAIN, rf_y)\n",
    "loss_xg = rf_y - xg.predict(TRAIN)\n",
    "lg.fit(TRAIN, rf_y)\n",
    "loss_lg = rf_y - lg.predict(TRAIN)\n",
    "ct.fit(TRAIN, rf_y)\n",
    "loss_ct = rf_y - ct.predict(TRAIN)\n",
    "\n",
    "\n",
    "catX = ct.predict(TEST)\n",
    "xgX = xg.predict(TEST)\n",
    "lgX = lg.predict(TEST)\n",
    "res = np.c_[xgX,lgX,catX]\n",
    "e = np.array([1/np.mean(loss_xg),1/np.mean(loss_lg),1/np.mean(loss_ct)])\n",
    "y_pred = np.sum(res*e,axis=1)/sum(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.read_csv(PATH + 'happiness_submit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "out['happiness'] = y_pred\n",
    "out.to_csv(\"happiness_submit.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2968, 2)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     4\n",
       "1     4\n",
       "2     4\n",
       "3     5\n",
       "4     4\n",
       "5     5\n",
       "6     4\n",
       "7     4\n",
       "8     4\n",
       "9     4\n",
       "10    4\n",
       "11    4\n",
       "12    4\n",
       "13    2\n",
       "14    4\n",
       "15    4\n",
       "16    4\n",
       "17    4\n",
       "18    4\n",
       "19    5\n",
       "Name: happiness, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>happiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8001</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8002</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8003</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8004</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8005</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  happiness\n",
       "0  8001          5\n",
       "1  8002          5\n",
       "2  8003          5\n",
       "3  8004          5\n",
       "4  8005          5"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/willer/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cat mse: 0.5144032237113016\n",
      "light mse: 0.5246388446214709\n",
      "xg mse: 0.5298154985368313\n",
      "gbdt mse: 0.5193542400891656\n",
      "[0.27305013 0.24045675 0.22144827 0.26199023]\n",
      "lr mse: 0.5174393144769724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/willer/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cat mse: 0.45049168693853353\n",
      "light mse: 0.44853289149980635\n",
      "xg mse: 0.45406824819921976\n",
      "gbdt mse: 0.457108785796664\n",
      "[0.25762387 0.26508132 0.24448327 0.23708497]\n",
      "lr mse: 0.44829232066307545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/willer/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cat mse: 0.4025580545075893\n",
      "light mse: 0.39798888520938375\n",
      "xg mse: 0.4072976341222525\n",
      "gbdt mse: 0.4034475085214292\n",
      "[0.24596639 0.26614931 0.2306685  0.25136806]\n",
      "lr mse: 0.3984375115754876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/willer/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cat mse: 0.45559896465821087\n",
      "light mse: 0.4653840765647241\n",
      "xg mse: 0.46100188143063087\n",
      "gbdt mse: 0.45874896150019173\n",
      "[0.26422511 0.2335437  0.24507041 0.26014051]\n",
      "lr mse: 0.4554972144727143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/willer/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cat mse: 0.42037367364599626\n",
      "light mse: 0.4198606821280977\n",
      "xg mse: 0.4290188920730493\n",
      "gbdt mse: 0.42902520458691024\n",
      "[0.26236195 0.26553933 0.23244594 0.23445588]\n",
      "lr mse: 0.42057261975478777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/willer/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cat mse: 0.4080924501724123\n",
      "light mse: 0.4122033421642622\n",
      "xg mse: 0.42134545106901367\n",
      "gbdt mse: 0.4257063827144742\n",
      "[0.27976783 0.2692486  0.23400263 0.22469713]\n",
      "lr mse: 0.4110654475297955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/willer/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cat mse: 0.4926297792532945\n",
      "light mse: 0.502844325280201\n",
      "xg mse: 0.5038668479539075\n",
      "gbdt mse: 0.5092957572004748\n",
      "[0.28036053 0.24847667 0.24208909 0.22761618]\n",
      "lr mse: 0.4978969350251835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/willer/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cat mse: 0.4896351107053426\n",
      "light mse: 0.4939943554900641\n",
      "xg mse: 0.49651619741898884\n",
      "gbdt mse: 0.5034686982225933\n",
      "[0.2684456  0.25437456 0.24495172 0.22491243]\n",
      "lr mse: 0.49117346285123087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/willer/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cat mse: 0.4441843235275523\n",
      "light mse: 0.45983459406105315\n",
      "xg mse: 0.44506037493686873\n",
      "gbdt mse: 0.45383707066431234\n",
      "[0.27086827 0.21909598 0.26754736 0.24086546]\n",
      "lr mse: 0.44628694243051065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/willer/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cat mse: 0.49382838169211013\n",
      "light mse: 0.49773527223459996\n",
      "xg mse: 0.4915891804338228\n",
      "gbdt mse: 0.5006116667048904\n",
      "[0.25517484 0.2427284  0.26485871 0.2376247 ]\n",
      "lr mse: 0.49161591518618847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/willer/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cat mse: 0.4377725002033474\n",
      "light mse: 0.44428059718587704\n",
      "xg mse: 0.44188402555821077\n",
      "gbdt mse: 0.44782351731362824\n",
      "[0.26231828 0.24740172 0.25086492 0.23767766]\n",
      "lr mse: 0.43836370062995345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/willer/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cat mse: 0.48536210132539664\n",
      "light mse: 0.4819013944449417\n",
      "xg mse: 0.49518798940428504\n",
      "gbdt mse: 0.4993214164890169\n",
      "[0.26807668 0.28237971 0.23648503 0.22526109]\n",
      "lr mse: 0.4826266982969688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/willer/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cat mse: 0.45491855592508634\n",
      "light mse: 0.4556318435524804\n",
      "xg mse: 0.4530331155545826\n",
      "gbdt mse: 0.457706715741354\n",
      "[0.24643297 0.24648417 0.25524588 0.23969911]\n",
      "lr mse: 0.449446904853177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/willer/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cat mse: 0.4608407561509579\n",
      "light mse: 0.46869886997155735\n",
      "xg mse: 0.46673526479853544\n",
      "gbdt mse: 0.47190987561415015\n",
      "[0.26865798 0.24248698 0.24777329 0.23232831]\n",
      "lr mse: 0.4624142439746409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/willer/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cat mse: 0.4210983915994417\n",
      "light mse: 0.4244474502100046\n",
      "xg mse: 0.4126546181067205\n",
      "gbdt mse: 0.4350515884701965\n",
      "[0.25301088 0.24250878 0.28554764 0.21227785]\n",
      "lr mse: 0.4184334559202827\n",
      "\n",
      "catmse: 0.45545253026777155\n",
      "\n",
      "\n",
      "lightmse: 0.4598651616412349\n",
      "xgmse: 0.4606050146397946\n",
      "gbdtmse: 0.46482782597529676\n",
      "lrmse: 0.45530417917606464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/willer/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/willer/anaconda3/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-ed263cee527b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0mxg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0mlight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0mgbdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    394\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(PATH + \"happiness_train_complete.csv\",encoding=\"GB2312\")\n",
    "df = df.sample(frac=1,replace=False,random_state=11)\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "df = df[df[\"happiness\"]>0]\n",
    "Y = df[\"happiness\"]\n",
    "df[\"survey_month\"] = df[\"survey_time\"].map(lambda line:line.split(\" \")[0].split(\"/\")[1]).astype(\"int64\")\n",
    "df[\"survey_day\"] = df[\"survey_time\"].map(lambda line:line.split(\" \")[0].split(\"/\")[2]).astype(\"int64\")\n",
    "df[\"survey_hour\"] = df[\"survey_time\"].map(lambda line:line.split(\" \")[1].split(\":\")[0]).astype(\"int64\")\n",
    "X = df.drop(columns=[\"id\",\"index\",\"happiness\",\"survey_time\",\"edu_other\",\"property_other\",\"invest_other\"])\n",
    "\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import LinearRegression,Lasso,Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "kfold = KFold(n_splits=5, shuffle = True, random_state= 12)\n",
    "catmse = []\n",
    "lightmse = []\n",
    "xgmse = []\n",
    "gbdtmse = []\n",
    "lrmse = []\n",
    "i = 0\n",
    "for train, test in kfold.split(X):\n",
    "    X_train = X.iloc[train]\n",
    "    y_train = Y.iloc[train]\n",
    "    X_test = X.iloc[test]\n",
    "    y_test = Y.iloc[test]\n",
    "    \n",
    "    cat = CatBoostRegressor(colsample_bylevel=0.1,thread_count=6,silent=True,iterations=800, \n",
    "                          depth=5, \n",
    "                          learning_rate=0.051, \n",
    "                          loss_function='RMSE',\n",
    "                          l2_leaf_reg = 3)\n",
    "    xg = XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=0.1,\n",
    "           colsample_bytree=0.971, gamma=0.11, learning_rate=0.069, max_delta_step=0,\n",
    "           max_depth=3, min_child_weight=1, missing=None, n_estimators=499,\n",
    "           n_jobs=-1, nthread=50, objective='reg:linear', random_state=0,\n",
    "           reg_alpha=0.1, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "           silent=True, subsample=1.0)\n",
    "    gbdt = GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
    "                 learning_rate=0.051, loss='ls', max_depth=4, max_features=10,\n",
    "                 max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "                 min_impurity_split=None, min_samples_leaf=1,\n",
    "                 min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                 n_estimators=600, presort='auto', random_state=3,\n",
    "                 subsample=0.98, verbose=0, warm_start=False)\n",
    "    \n",
    "    light = LGBMRegressor(n_jobs=-1,learning_rate=0.051,\n",
    "                      n_estimators=400,\n",
    "                      num_leaves=11,\n",
    "                      reg_alpha=2.0, \n",
    "                      reg_lambda=2.1,\n",
    "                      min_child_samples=6,\n",
    "                      min_split_gain=0.5,\n",
    "                      colsample_bytree=0.2\n",
    "                     )\n",
    "    \n",
    "    cat.fit(X_train, y_train)\n",
    "    xg.fit(X_train, y_train)\n",
    "    light.fit(X_train, y_train)\n",
    "    gbdt.fit(X_train.fillna(-8), y_train)\n",
    "    \n",
    "    catX = cat.predict(X_test)\n",
    "    cat_mse = mean_squared_error(y_true=y_test,y_pred=catX)\n",
    "    print(\"\\ncat mse:\",cat_mse)\n",
    "    catmse.append(cat_mse)\n",
    "\n",
    "    lightX = light.predict(X_test)\n",
    "    light_mse = mean_squared_error(y_true=y_test,y_pred=lightX)\n",
    "    print(\"light mse:\",light_mse)\n",
    "    lightmse.append(light_mse)\n",
    "    \n",
    "    xgX = xg.predict(X_test)\n",
    "    xg_mse = mean_squared_error(y_true=y_test,y_pred=xgX)\n",
    "    print(\"xg mse:\",xg_mse)\n",
    "    xgmse.append(xg_mse)\n",
    "    \n",
    "    gbdtX = gbdt.predict(X_test.fillna(-8))\n",
    "    gbdt_mse = mean_squared_error(y_true=y_test,y_pred=gbdtX)\n",
    "    print(\"gbdt mse:\",gbdt_mse)\n",
    "    gbdtmse.append(gbdt_mse)\n",
    "    \n",
    "    res = np.c_[catX,lightX,xgX,gbdtX]\n",
    "    lr = Ridge(fit_intercept=False, alpha=75)\n",
    "    lr.fit(res,y_test)\n",
    "    print(lr.coef_)\n",
    "\n",
    "    y_pred = lr.predict(res)\n",
    "    lr_mse = mean_squared_error(y_true=y_test,y_pred=y_pred)\n",
    "    print(\"lr mse:\",lr_mse)\n",
    "    lrmse.append(lr_mse)\n",
    "    joblib.dump(filename=\"lr\"+str(i),value=lr)\n",
    "    i+=1\n",
    "    \n",
    "print(\"\\ncatmse:\",np.mean(catmse))\n",
    "print(\"\\n\\nlightmse:\",np.mean(lightmse))\n",
    "print(\"xgmse:\",np.mean(xgmse))\n",
    "print(\"gbdtmse:\",np.mean(gbdtmse))\n",
    "print(\"lrmse:\",np.mean(lrmse))\n",
    "\n",
    "    \n",
    "df2 = pd.read_csv(PATH + \"happiness_test_complete.csv\",encoding=\"GB2312\")\n",
    "df2[\"survey_month\"] = df2[\"survey_time\"].map(lambda line:line.split(\" \")[0].split(\"/\")[1]).astype(\"int64\")\n",
    "df2[\"survey_day\"] = df2[\"survey_time\"].map(lambda line:line.split(\" \")[0].split(\"/\")[2]).astype(\"int64\")\n",
    "df2[\"survey_hour\"] = df2[\"survey_time\"].map(lambda line:line.split(\" \")[1].split(\":\")[0]).astype(\"int64\")\n",
    "out = df2[[\"id\"]]\n",
    "X_test = df2.drop(columns=[\"id\",\"survey_time\",\"edu_other\",\"property_other\",\"invest_other\"])\n",
    "prediction = []\n",
    "\n",
    "cat = CatBoostRegressor(colsample_bylevel=0.1,thread_count=6,silent=True,iterations=800, \n",
    "                      depth=5, \n",
    "                      learning_rate=0.051, \n",
    "                      loss_function='RMSE',\n",
    "                      l2_leaf_reg = 3)\n",
    "xg = XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=0.1,\n",
    "       colsample_bytree=0.971, gamma=0.11, learning_rate=0.069, max_delta_step=0,\n",
    "       max_depth=3, min_child_weight=1, missing=None, n_estimators=499,\n",
    "       n_jobs=-1, nthread=50, objective='reg:linear', random_state=0,\n",
    "       reg_alpha=0.1, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=1.0)\n",
    "gbdt = GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
    "             learning_rate=0.051, loss='ls', max_depth=4, max_features=10,\n",
    "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "             min_impurity_split=None, min_samples_leaf=1,\n",
    "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "             n_estimators=600, presort='auto', random_state=3,\n",
    "             subsample=0.98, verbose=0, warm_start=False)\n",
    "\n",
    "light = LGBMRegressor(n_jobs=-1,learning_rate=0.051,\n",
    "                  n_estimators=400,\n",
    "                  num_leaves=11,\n",
    "                  reg_alpha=2.0, \n",
    "                  reg_lambda=2.1,\n",
    "                  min_child_samples=6,\n",
    "                  min_split_gain=0.5,\n",
    "                  colsample_bytree=0.2\n",
    "                 )\n",
    "\n",
    "cat.fit(X, Y)\n",
    "xg.fit(X, Y)\n",
    "light.fit(X, Y)\n",
    "gbdt.fit(X.fillna(-8), Y)\n",
    "\n",
    "catX = cat.predict(X_test)\n",
    "lightX = light.predict(X_test)\n",
    "xgX = xg.predict(X_test)\n",
    "gbdtX = gbdt.predict(X_test.fillna(-8))\n",
    "res = np.c_[catX,lightX,xgX,gbdtX]\n",
    "prediction.append(lr.predict(res))\n",
    "    \n",
    "a = np.array(prediction)\n",
    "def cut(arr):\n",
    "    arr2 = []\n",
    "    for x in arr:\n",
    "        if x<1:\n",
    "            arr2.append(1)\n",
    "        elif x>5:\n",
    "            arr2.append(5)\n",
    "        else :\n",
    "            arr2.append(x)\n",
    "    return arr2\n",
    "out[\"happiness\"] = np.mean(np.array(prediction),axis=0)\n",
    "# out.to_csv(\"happiness_submit.csv\",index=False)\n",
    "# print(\"done\")\n",
    "\n",
    "out[\"happiness\"] = cut(np.sum((1/np.array(lrmse)*a.T),axis=1)/np.sum(1/np.array(lrmse)))\n",
    "out.to_csv(\"happiness_submit.csv\",index=False)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
